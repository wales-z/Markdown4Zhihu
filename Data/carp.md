# A Capsule Network for Recommendation and Explaining What You Like and Dislike

## 摘要

用户评论包含针对用户对物品特征的偏好的丰富语义。最近，通过利用评论进行推荐，已经提出了许多基于深度学习的解决方案。 这些作品主要采用注意力机制来识别对评分预测很重要的词或 aspect 。 然而，如果不检查评论细节，仍然很难根据用户持有的观点和程度来了解用户是喜欢还是不喜欢物品的某个 aspect 。 在这里，我们将用户持有的一个观点 (viepoint) 和物品的一个 aspect 组成的一个 pair 视为一个逻辑单元。 通过从评论中发现信息逻辑单元 (informative logic units) 并解析其相应的情绪来推理评级行为可以实现更好的评分预测和解释。

为此，在本文中，我们提出了一种基于胶囊网络 (capsule network) 的使用用户评论的评分预测模型，名为 CARP。 对于每个用户-物品对 (pair)，CARP 从评论中提取具信息逻辑单元并推断它们相应的情绪。该模型首先分别从用户和物品评论文档中提取观点和 aspect 。 然后我们根据每个逻辑单元的组成观点和 aspect 来推导出每个逻辑单元的表示。 提出了一种具有新颖的 Routing by Bi-Agreement 机制的情感胶囊架构，以识别具信息逻辑单元和用户-物品级别的基于情感的表示，以进行评分预测。 在七个具有不同特征的真实世界数据集上进行了广泛的实验。我们的结果表明，就预测精度而言，所提出的 CARP 比最近提出的SOTA模型获得了显着的性能提升。进一步的分析表明，我们的模型可以在更精细的粒度级别上成功地发现可解释的原因。

## 1 引言

许多电子商务平台允许用户以评论的形式分享她购买商品的体验，还有数字评分，例如 Yelp 和亚马逊（参考图 1）。这些文字评论在支持个性化推荐的电子商务平台中发挥了越来越重要的作用。 许多推荐系统是通过利用评论 [1, 3–6, 15, 18, 20, 24, 26, 27, 29, 37, 39] 中涵盖的语义信息来开发的，而非使用自然的稀疏的用户-物品评分，这导致了显着的性能提升。

![image-20211028205248059](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211028205248059.png)

【图 1】

早期的解决方案选择对评论采用主题建模或非负矩阵分解，并在语义上表示用户/物品 [1, 18, 20, 26, 29]。这种建模范式最近被深度学习技术的复兴所压制。具体而言，在上下文信息上的连续实值向量表示和语义组合的支持下，最新的基于评论的深度学习模型显着推动了最先进技术的前沿。比如 DeepCoNN [39]、D-Attn [24]、TransNet [3]、ANR [7] 和 MPCN [27]。

尽管通过这些努力取得了显着的性能提升，但这些模型并不能解释用户在进行评分时真正发生的事情。 假设用户会对物品的不同 aspect 给予不同的重视是合理的。 同样，不同的用户会在不同程度上关心物品的特定 aspect  [6]。当我们进一步考虑情感信息时，事情变得更加有趣。 用户可以通过考虑不同的 aspect 来对物品持有相反的意见。因此，整个评分可以被视为一个物品的相对优点 (relative merit) 的指示（即对优点和致命缺点的妥协）。图 1 中的示例属于这类。

在这里，我们将用户撰写的所有评论都称为用户文档。用户文档主要包含她对不同物品的个人观点。例如，用户可能更喜欢 outdoor activities，因此会欣赏物品的相关 aspect （例如，low profile、easy storage）。此外，可以通过合并为该物品编写的所有评论来形成物品文档。 一个物品文档可以被认为是物品各个 aspect 的整合 (summary)，其中重要的 aspect 可以很容易地暴露出来 [19, 26]。 在这里，为了推理评分行为，我们希望理解：用户是否喜欢或不喜欢一个物品，根据他/她持有的观点以及程度。

为此，在本文中，我们提出了一种基于胶囊网络的利用用户评论的评分预测模型，名为 CARP。 详细地说，CARP 由两部分组成：观点和 aspect 提取以及情感胶囊。首先，采用堆叠在卷积层上的自注意力变体来分别提取用户和物品文档中提到的观点和 aspect 。 给定用户-物品对，我们将用户观点和物品 aspect 打包在一起以形成逻辑单元。 这个概念可以代表评分行为背后的原因。 然而，并非所有由这种简单配对形成的逻辑单元在现实世界中都有意义。
我们将语义上合理的逻辑单元称为信息逻辑单元。 例如，一个关于outdoor enthusiast 的观点和一个关于 easy storage 的物品 aspect 将形成一个信息逻辑单元。 另一方-面 ，elegant appearance 的观点和 easy storage 的组合显然不太合理。

为了识别信息逻辑单元，我们导出所有可能的逻辑单元的表示并将它们输入到情感胶囊中。具体来说，我们利用一个积极的胶囊和一个消极的胶囊来表示用户对物品的态度。通过设计一种新的迭代路由机制——Routing by Bi-Agreement，我们使两个情感胶囊能够共同识别用户分别持有的正面和负面情绪的信息逻辑单元。 这两个情感胶囊产生的输出向量分别编码用户喜欢或不喜欢该物品的程度。 同时，向量长度表明了这两种情绪中每一种的概率。 然后，对于给定的用户-物品对，根据这些幅度和两个情绪极性的几率估计总体评分。最后，我们需要强调的是，CARP 是以评论驱动和端到端的方式工作的。为了保证正确的情感建模，我们将 CARP 转换为多任务学习过程，以便利用评分提供的隐式情感信息。具体来说，我们引入情感匹配过程，根据评分数值对评论的情感进行分类。请注意，CARP 的训练不需要人工标注或外部 NLP 工具。

我们的工作与之前的工作有着根本的不同，因为我们的目标是在用户观点、物品 aspect 和情感之间建立一个桥梁，将评论和评分同原因 (cause) 联系起来。回到现有的基于深度学习的解决方案，表示学习过程仅突出评论中的重要词或 aspect  [7, 19, 24, 27]。 很难分别推断出用户在其脑海中应用了哪些规则和效果。总体而言，我们的主要贡献总结如下：

- 我们提出了一种新颖的深度学习模型，该模型利用评论进行评分预测和解释。 这是首次尝试通过联合考虑用户观点、物品 aspect 和情绪，对电子商务中评分行为的推理过程进行显式建模。
- 我们引入了一个基于胶囊的架构来共同识别信息逻辑单元并估计它们在情感分析 aspect 的影响。 我们进一步提出了 Routing by Bi-Agreement，这是一种新的胶囊网络迭代式动态路由过程。
- 为了在不使用任何外部资源的情况下实现情感建模，提出了一种多任务学习过程进行模型优化，它可以成功地利用评分提供的隐含情感信息。
- 在具有不同特征的七个真实世界数据集上，我们的结果证明了所提出的 CARP 在评分预测的准确性、性能鲁棒性和细粒度解释 aspect 的优越性

## 2 相关工作

这部分简单回顾与我们此次工作高度相关的三个不同领域。

### 2.1 基于评论的推荐系统

近年来，利用用户评论来提高推荐的准确性和可解释性已经被许多工作研究和验证 [1, 3, 4, 6, 8, 15, 18, 20, 24, 26, 27, 29, 37,  39]。 在早期，人们做了很多努力来使用主题建模技术从评论中提取语义特征 [2, 14]。
这些作品将潜在语义主题整合到因子学习 (factor learning) 模型中 [1, 18, 20, 26, 29]。TLFM 提出了两个单独的因子学习模型来利用用户和物品的情感一致性和文本一致性 [25]。 然后他们将这两种观点统一起来进行评分预测。 然而，所提出的解决方案需要将目标用户-物品对的评论作为输入，这是不切实际的 (?)，这将推荐任务转变为情感分析任务。CDL [30] 建议将 SADE 与评论和 PMF [23] 结合起来。由于在这些作品中使用了词袋表示模式，由于缺少上下文信息，预计会出现大量信息丢失。

最近，提出了许多工作来对评论中的上下文信息进行建模，以便使用深度学习技术进行更好的推荐 [3, 4, 24, 27, 39]。 卷积神经网络 (CNN) [16] 和循环神经网络 (RNN) [9, 21] 主要用于将语义上下文信息合成为连续实值向量表示。ConvMF 与 CDL 共享相同的架构，并使用 CNN 从物品描述中提取物品特征 [15]。TARMF 使用同时从用户文档和物品文档中提取的特征来校准因子学习范式中的潜在因子 [19]。DeepCoNN 使用并行 CNN 网络从用户和物品文档中发现语义特征 [39]，然后将提取的特征输入因子分解机进行评分预测。TransNet 使用额外的变换层强化了 DeepCoNN，以推断在评分预测期间不可用的目标用户-物品评论的表示 [3]。  D-Attn 利用全局和局部注意力机制来识别评论文档中的重要单词以进行评分预测 [24]。请注意，每条评论都包含不同的语义信息。  NARRE 认为应该对不同的用户-物品对的评论进行不同的处理，并建议采用注意力机制来选择有用的评论进行评分预测 [4]。同样，MPCN 利用基于指针的共同注意模式来实现多层次信息选择。在 MPCN [27] 中，重要评论及其重要词都可以被识别出从而实现更好的评分预测。

### 2.2 基于 Aspect 的推荐系统

对于透明推荐 (transparent recommendation)，许多工作致力于从评论中建模用户意见，即基于 aspect 的推荐系统，这可以进一步分为两类。 第一类求助于使用外部 NLP 工具从评论中提取 aspect 和情绪。例如，EFM 和 MTER 通过短语级 NLP 工具生成情感词典 [31, 38]。类似地，TriRank 利用提取的 aspect 来构建用户和物品的三方图 (tripartite) [11]。 这些工作在很大程度上依赖于外部工具包的性能。

第二类旨在通过设计内部组件从评论中自动推断出可解释的 aspect 。JMARS 通过使用主题建模进行协同过滤来学习用户和物品的 aspect 表示 [8]。AFLM 在评论上提出了一个 aspect 感知主题模型，以学习主题空间中用户和物品的不同 aspect  [6]。最近，ANR 在神经架构中提出了一种共同注意机制，以端到端的方式自动估计 aspect 级别的评分和 aspect级别的重要性 [7]。

上述许多基于评论和基于 aspect 的解决方案旨在识别重要的词或 aspect ，以增强推荐并促进解释。 然而，他们仅针对评级行为背后的复杂推理过程绘制了一幅不完整的图画。他们无法根据用户持有的观点和程度来判断用户是喜欢还是不喜欢物品的某个 aspect 。在这项工作中， CARP 可以看作是填补缺失部分的初步步骤。

### 2.3 用于NLP的胶囊网络

胶囊网络使用一种分层 (hierarchical) 架构来模拟潜在特征之间的复杂关系 [13]。 胶囊中的附属 (affiliated) 动态路由（Routing by Agreement）机制确保可以选择性地聚合低级特征以形成高级特征 [22]。最近，这个概念已经应用于一些 NLP 任务，包括关系提取 [36]、文本分类 [35]、零样本 (zero-shot) 用户意图检测 [33] 和多任务学习 [34]。 在这项工作中，我们利用基于胶囊的架构和新提出的 Routing by Bi-Agreement（RBiA）机制来共同实现多个目标。  RBiA 计算胶囊间 (inter) 和胶囊内 (intra) 的协议以推导出胶囊的输出，这将是对现有研究的有用补充

## 3 所提出的模型

这部分展示所提出的胶囊网络 CARP，图 2 说明了其整体架构。

![image-20211030161454233](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211030161454233.png)

### 3.1 观点和 Aspect 提取

如前所述，用户文档 $D_u$ 是通过合并用户 $u$ 撰写的所有评论而形成的。并且可以以类似的方式形成物品文档 $D_i$ 。我们首先分别从相应的文档中提取用户观点和物品 aspect 。在这里，我们详细介绍了 CARP 中的观点提取。aspect 的提取也是相同的过程。

#### 3.1.1 上下文编码

给定用户文档 $D_u = (w_1,w_2, ...,w_l )$ 其中 $l$ 是文档长度（以单词数表示），我们首先将每个单词投影到其嵌入 (embedding) 表示：$\bold D_u = (\bold e_1, ..., \bold e_l )$。 这里，$\bold e_j \in \mathbb R^d$ 是第 $j$ 个位置的词的嵌入向量，$d$ 是嵌入大小。然后，为了提取每个单词周围可能的 aspect-specific 的信息，我们使用 ReLU（即整流线性单元）作为激活函数执行卷积操作。具体来说，上下文是通过在每个单词的两侧使用跨越 $\frac {c-1} {2}$ 个单词的窗口进行编码的。得到的潜在特征向量是 $[\bold c_1, ..., \bold c_l ]$ 并且 $\bold c_j \in \mathbb R^n$ 是第 $j$ 个词的潜在上下文特征向量，$n$ 是 filter 的数量。

#### 3.1.2 自注意力

直觉上，并不是文档中的所有单词对于每个观点都很重要。 为了识别 $\bold c_j$ 携带的哪些特征与每个观点相关，我们利用特 viewpoint-specific 的门控机制：
$$
\bold s_{u,x,j} = \bold c_j \odot \sigma(\bold W_{x,1} \bold c_j + \bold W_{x,2} \bold q_{u,x} + \bold b_x)
\tag1
$$
其中 $\bold W_{x,1}, \bold W_{x,2} \in \mathbb R^{n \times n},\bold b_x \in \mathbb R^n$ 分别是第 $x$ 个观点的变换矩阵和偏置向量。$\sigma$ 是sigmoid 激活函数，$\odot $ 是 element-wise 乘积运算，$\bold q_{u,x}$ 是第 $x$ 个观点的嵌入，由所有用户共享，通过模型优化来学习。然后，我们通过投影从 $\bold s_{u,x,j}$ 中提取上下文观点表示 $\bold p_{u,x,j}:$$ \bold p_{u,x,j} = \bold W_p \bold s_{u,x,j} $ 其中 $\bold W_p \in \mathbb R^{k×n}$ 是所有观点共享的变换矩阵。在相似的上下文中，同一个词的 viewpoint-specific 语义可能不同，这是合理的。例如，在“电池可以持续很长时间”和“等待时间很长”的上下文中，同一个词“长”持有相反的情绪。aspect-specific 的门控和投影通过消除每个单词的语义歧义来帮助我们精确地提取与观点相关的信息。

自然地，评论中提到的 viewpoint-specific 的词越多，用户所持有的观点就越坚定。例如，实用主义者经常提到“性能”、“耐用”和“实用”，而“可爱”和“美学 (aesthetics) ”则应主导了注重外观的用户撰写的评论。在 CARP 中，我们建议利用 self-attention 机制从文档中推导出用户的观点。具体来说，我们首先通过取用户文档中构成 viewpoint-specific 上下文嵌入的平均总和（即 $\bold v_{u,x} = \frac {1} {l} \sum_j \bold p_{u,x,j}$ ）来推导出观点的基本表示。然后内部注意力  (intra-attention)  权重计算为 $ attn_{u,x,j} = {\rm softmax} (\bold p^⊤_{ u,x,j} \bold  v_{u,x}$ )。 最后，观点 $\bold v_{u,x}$ 被表示为：
$$
\bold v_{u,x} = \sum_j attn_{u,x,j} \bold p_{u,x,j}
\tag2
$$
内部注意机制使观点提取能够捕获对不同观点始终重要的特征。为了模型简单，我们将用户的观点编号和物品的 aspect 编号限制为相同。按照相同的流程，我们从具有不同参数集（例如，卷积操作、aspect 嵌入和门控机制）的相应物品文档中提取物品的 M 个 aspect 。

#### 3.1.3 逻辑单元表示 

通过上面提取的用户观点和物品 aspect ，我们需要确定用户在对特定物品进行评分时应用的规则。实际上，对于决策而言，这些规则表现为各种原因及其结果。 用户和物品应该出现在一个原因的两侧是合理的。 因此，将用户观点与物品 aspect 打包在一起形成原因，称为逻辑单元。具体来说，给定用户 $u$ 的第 $x$个观点 $\bold v_{u,x}$和物品 $i$ 的第 $y$ 个 aspect $\bold a_{i,y}$，对应逻辑单元$ g_{x,y} $ 的表示 $\bold g_{x,y}$ 的推导如下：
$$
\bold g_{x,y} = [(\bold v_{u,x} - \bold a_{i,y}) \oplus (\bold v_{u,x} \odot \bold a_{i,y})]
\tag3
$$
其中 $\oplus$ 是向量拼接操作。显然，等式 3 中采用的二阶特征交互可以提供更多的表达能力来编码观点和 aspect 之间的隐藏相关性 [12, 17]。 我们还选择包含 $\bold v_{u,x}$ 和 $\bold a_{i,y}$ 的潜在表示来表示 $g_{x,y}$ 。然而，在我们的经验评估中，没有观察到进一步的性能提升。

### 3.2 情感胶囊

假设每个用户/物品有 $M$ 个观点/ asepct ，我们可以形成 $M^2$ 个逻辑单元，每个用户-物品对随机配对。然而，并非所有可能的逻辑单元在现实世界中都是合理的或有意义的。在这里，我们将信息逻辑单元定义为语义上合理的单元。也就是说，一个信息逻辑单元应该在语义上保持其构成观点和 asepct 的显式或隐式蕴涵关系（或关联）。因此，我们的目标之一是确定信息逻辑单元。此外，我们的目标是根据什么信息逻辑单元以及在多大程度上推断用户是否喜欢和不喜欢某个物品。 在这里，我们提出了一种基于 [22] 的胶囊架构，以一次性实现所有这些目标。

具体来说，采用两个情感胶囊，即正胶囊和负胶囊，共同选择一些逻辑单元作为信息单元并解析它们的情感。具体来说，在每个情感胶囊中，每个逻辑单元的潜在情感特征为 $\bold t_{s,x,y} = \bold W_{s,x,y} \bold g_{x,y}$ ，其中 $ s \in S$ 和 $S = \{\rm pos, neg\}$ 指的是两种情感 , $\bold W_{s,x,y} \in \mathbb R^{k\times 2k}$ 是权重矩阵，$\bold t_{s,x,y}$ 是逻辑单元 $g_{x,y}$ 的潜在特征向量。然后，带有情感 $s$ 的胶囊将所有特征向量 $\{\bold t_{s,x,y} |x,y \in 1...M \}$ 作为输入，并通过迭代动态路由过程导出其输出向量。实际上，我们可以将每个情感胶囊的输出视为这些特征向量的加权和：
$$
\bold s_{s,u,i} = \sum_{x,y} c_{s,x,y} \bold t_{s,x,y}
\tag4
$$
其中 $ c_{s,x,y}$ 是耦合 (coupling) 系数，表示逻辑单元 $g_{x,y}$ 在确定情绪 $s$（即喜欢或不喜欢） asepct 的重要性以及程度（参考等式 7）。也就是说，情绪胶囊有望在该情绪中捕获用户的整体意见。此外，胶囊还根据其输出向量的长度对胶囊所表示的概念的存在（或激活）概率进行编码 [22]。 具体来说，非线性挤压 (squashing) 函数将 $\bold s_{s,u,i}$ 转换为 $\bold o_{s,u,i}$ ，其长度落在 $(0, 1)$ 的范围内。
$$
\bold o_{s,u,i} = \frac{||\bold s_{s,u,i}||^2}{1+||\bold s_{s,u,i}||^2} \frac {\bold s_{s,u,i}} {||\bold s_{s,u,i}||}
\tag5
$$
其中 ∥ · ∥ 表示向量的长度。请注意，在等式 5 中，$\bold s_{s,u,i}$ 的方向保留在 $\bold o_{s,u,i}$ 中。 我们期望 $\bold o_{s,u,i}$ 编码关于用户喜欢或不喜欢物品 $i$ 的程度的答案。 此外，我们利用 $\bold o_{s,u,i}$ 的长度来从概率的角度回答用户 $u$ 是否对物品 $i$ 持有情绪 $s$（即，回答用户 $u$ 是喜欢还是不喜欢物品 $i$）。

#### 3.2.1 Routing by Agreement 的局限性

公式 4 中 $c_{s,x,y}$ 的值是通过迭代 Routing by Agreement 算法计算得出的，正如在原始胶囊架构 [22] 中使用的那样，核心步骤是迭代计算一致性分数 $b_{s,x,y}$，表明 $\bold t_{s,x,y}$  与同一情感胶囊内的其他特征向量之间的相关性。然后，使用 softmax 操作来推导逻辑单元关于两个胶囊的耦合系数，如下所示
$$
c_{s,x,y} = \frac {\exp (b_{s,x,y})}{\sum_{s \in S} \exp (b_{s,x,y})}
\tag6
$$
在等式 6 中，我们可以看到，当一个逻辑单元与这个胶囊的一致性比另一个胶囊的一致性更高时，它会对情感胶囊的输出做出更多贡献。回想一下，我们需要识别表示评分行为背后原因的信息逻辑单元。基于等式 6，非信息逻辑单元仍然会造成很大的模糊，从而损害胶囊的情感抽象能力。例如，在动态路由过程开始时，非信息逻辑单元会与两个胶囊产生负面一致性（-0.05 对 -0.9）。

然而，对于等式 6 中的 softmax 操作，该逻辑单元的耦合系数分别为 0.7 和 0.3。 较大的权重不可避免地会对第一个情感胶囊产生大量噪音，这会在以后的迭代中产生很大的不利影响（参考算法 1）。 从这个意义上说，CARP未能揭示推理过程和保证语义解释。为此，我们引入了Routing by Bi-Agreement。

#### 3.2.2 Routing by Bi-Agreement

让 $\neg s$ 表示与情感 $s$ 相比相反的情感，我们任务的合适的动态路由过程应具有以下三个属性：

(1) 如果 $b_{s,x,y}$ 在胶囊内相对较大，并且 $b_{s,x,y} > b  _{\neg s,x,y}$ ，则 $c_{s,x,y}$ 的值也应该更大； 

(2) 如果$b_{s,x,y}$ 在胶囊内部相对较大，但 $b_{s,x,y} < b_{\neg s,x,y}$ ，则 $c_{s,x,y}$ 的值应该很小；

(3) 如果 $b_{s,x,y}$ 在胶囊内部相对较小，则 $c_{s,x,y}$  的值也应该更小。

请注意，给定用户-物品对，从相关评论中提取的信息逻辑单元对解释评分行为具有不同的重要性。 此外，每个信息逻辑单元都应该只与一个单一的情绪相关联。在这里，给定用户-物品对，我们让 CARP 自动识别对每个情绪的重要信息逻辑单元，这由第一个和第二个属性以评论驱动的方式进行控制。另一 asepct ，正如上面提到的例子，预期非信息逻辑单元与两个情感胶囊的一致性非常低。第三个属性可以帮助我们抑制它们的影响。

![image-20211031215227595](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211031215227595.png)

【算法 1】

我们提出了Routing by Bi-Agreement（RBiA），这是一种新的迭代动态路由过程，具有上述三个属性。RBiA 被设计为通过同时考虑囊间和囊内视图中 $b_{s,x,y}$ 的相对大小来导出耦合系数 $c_{s,x,y}$。 这个动态过程的细节在算法 1 中描述。首先，RBiA 为两个情感胶囊上的每个逻辑单元分配相同的初始一致性 (agreement)（第 1-2 行）。然后，我们根据胶囊间比较（第 5 行）计算候选耦合系数 $ \check c_{s,x,y}$。另一方-面，另一个候选耦合系数 $\hat c_{s,x,y}$ 的计算方法类似，但是是通过比较胶囊内视图中的 $b_{s,x,y}$（第 6 行）。我们通过对每个情感胶囊内的 $ \check c_{s,x,y}$ 和 $\hat c_{s,x,y}$  的几何平均值执行L1 归一化来计算耦合系数 $c_{s,x,y}$（第7行）。几何平均数对于我们的任务来说是一个有吸引力的选择，因为 $\check c_{s,x,y }$ 或  $\hat c_{s,x,y}$ 的百分比变化将对几何平均数产生相同的影响。 通过考虑对一致性  $b_{s,x,y}$  的两种不同视图，可以清楚地看到 RBiA 可以满足上述三个属性。 请注意，每个耦合系数 $c_{s,x,y}$ 都根据特征向量 $\bold t_{s,x,y}$ 和当前迭代（第 12 行）的输出 $\bold o_{s,u,i}$ 之间的测量一致性进行更新。上次迭代计算的输出向量 $\bold o_{s,u,i}$ 用于评分预测，这将在下面描述。

### 3.3 评分预测和优化

给定输出 $\bold o_{s,u,i}$ ，我们计算用户 $u$ 为具有情感 $s$ 的物品 $i$ 给出的评分 $r_{s,u,i}$ 如下：

<img src="https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211030171959407.png" alt="image-20211030171959407" style="zoom:63%;" />

其中 $\bold w_s$ 是回归权重向量，$b_{s,3}$ 是偏置项，$\bold H_{s,1}, \bold H_{s,2} \in \mathbb R^{k×k}$ 是变换矩阵，$\bold b_{s,1}, \bold b_{s,2} \in \mathbb R^k$ 是偏置向量，$\bold 1$ 是所有元素都为 1 的向量。通过进一步考虑用户和物品的偏差，总评分的计算如下：
$$
\hat r_{u,i} = f_C(r_{pos,u,i} \cdot ||\bold o_{pos,u,i}|| - r_{neg,u,i} \cdot ||\bold o_{neg,u,i}||) + b_u + b_i
\tag{10}
$$
其中 $\hat r_{u,i}$ 是预测的评分，$b_u$ 和 $b_i$ 分别是用户 $u$ 和物品 $i$ 的对应偏置，函数 $f_C (x  ) = 1 + \frac {C−1} {1+\exp(−x )}$ 是 sigmoid 函数的变体，产生一个在 [1,C] 的目标评分范围内的值。 

这里，我们根据向量长度明确考虑给定用户-物品对的情绪 $s$ 的存在。 此外，利用一层 highway 网络（参考公式 8 和 9）为复杂场景建模提供了更大的灵活性。例如，用户会由于某种原因而在某种程度上不喜欢某个物品。但是，由于一些更重要的原因，该用户也会给出高评分（参考图 1）

**多任务学习**。对于模型优化，我们使用均方误差（MSE）作为指导参数学习的目标
$$
L_{sqr} = \frac {1}{O} \sum_{(u,i)\in O} (r_{u,i}- \hat r_{u,i})^2
\tag {11}
$$
其中 $O$ 表示观察到的用户-物品评分对的集合，$r_{u,i}$ 是用户 $u$ 给物品 $i$ 的评分。 请注意，我们在 CARP 中明确包含了一个特定的情感分析任务。 然而，仅通过匹配观察到的评分分数，CARP 的训练很容易陷入局部最优，这可能无法正确反映细粒度的情绪。 因此，我们引入了一个子任务来增强 CARP 中情感分析的能力。 具体来说，较低的评分表明用户肯定不喜欢该物品。类似地，由于用户对物品最满意，因此用户评分较高。因此，我们为每个观察到的用户-物品评分对分配一个标签 $s_{u,i}$。 当评级 $r_{u,i} > \pi, s_{u,i} = pos$; 否则，$s_{u,i} = neg$。也就是说，我们可以将 $O$ 分成两个不相交的子集 $O_{pos}$ 和 $O_{neg}$。$\pi$ 是一个预定义的阈值。然后我们利用情感分析任务作为另一个目标函数：
$$
L_{stm} = \frac{1}{O}(\sum_{(u,i)\in O} \max (0, \epsilon - ||\bold o_{s_{u,i}},u,i||))
\tag{12}
$$
其中 $\epsilon$ 是一个阈值，表示用户-物品对应该保持相应情绪的概率。虽然等式 12 提议的 CARP 更精确地学习执行情感分析的能力，但是，我们需要考虑数据不平衡问题。 也就是说，具有较低评级分数的用户-物品对的数量明显少于反面情况（即 |Opos | ≫ |Oneд |）。 这种不平衡问题会影响模型识别负面情绪。为了对负面情绪进行更多的监督来缓解这个问题，我们利用互斥原则 (mutual exclusion) 如下：
$$
\begin{align}
L_{stm} &= \frac{1}{O}(\sum_{(u,i)\in O} \max (0, \epsilon - ||\bold o_{s_{u,i}},u,i||)\\
&+ \max (0, ||\bold o_{\neg s_{u,i},u,i}-1+\epsilon||))
\end {align}
\tag{13}
$$
在等式 13 中，每个用户-物品对还应满足条件 $||\bold o_{\neg s_{u,i},u,i} ||≤ 1 − \epsilon$。 我们知道这种约束过于严格，在现实中是不真实的。 但是对负面情绪的更弱监督被用于模型优化。 换句话说，关于正面和负面情绪的反馈由每个用户-物品对提供。在我们的实验中，我们观察到 CARP 在预测阶段根据这一原则获得了合理的结果（参考第 4.3 节）。 在这项工作中，我们设置 $\epsilon = 0.8$。考虑到这两个目标函数，CARP 的最终目标函数是 $L_{sqr}$ 和 $L_{stm}$ 的线性融合
$$
L=\lambda \cdot L_{sqr} + (1-\lambda)\cdot L_{stm}
\tag{14}
$$
其中 $\lambda$ 是控制每个子任务重要性的可调节的参数。 我们使用 RMSprop [28] 以端到端的方式进行参数更新。

## 4 实验

在本节中，对来自三个不同来源的七个数据集进行了综合实验，以评估 CARP^1^ 的性能。

> 注释1: 代码地址：https://github.com/WHUIR/CARP

### 4.1 实验设置

#### 4.1.1 数据集

在我们的实验中，我们使用了来自三个来源的七个数据集：Amazon-5cores^2^ [10]、Yelp 和 RateBeer 网站。对于 Amazon-5cores 数据集，使用了来自不同领域的五个数据集（即乐器、办公产品、数字音乐、工具改进和视频游戏）。其他分别来自 Yelp 挑战网站^3^（第 11 轮）和 RateBeer 网站^4^（称为 Beer）。请注意，我们还在这两个数据集上采用了 5-core 设置：每个用户和物品至少有 5 条评论。 此外，我们只保留 Yelp 中从 2016 年到 2017 年的记录作为最终数据集，记为 Yelp16-17。 这些数据集中使用的目标评分范围是 [1, 5]^5^ ，因此我们设置 $C = 5$ 和 $\pi = 3$。

在所有数据集上，我们采用 [15] 中使用的相同预处理步骤。 然后，我们过滤掉包含空评论的评分记录。 表 1 给出了七个预处理数据集的详细统计数据。我们可以看到 $|O_{pos} |/|O_{neg}|$  （表 1 中的“pos/neg ratio”）在大多数数据集上都非常大。对于每个数据集，我们以 80:20 的比例随机构建训练集和测试集。此外，随机选择训练集中 10% 的记录作为超参数选择的验证集。请注意，训练集中至少包含每个用户/物品的一次交互。 验证和测试集中的目标评论被排除在外，因为它们在实际场景中不可用

> 注释2：http://jmcauley.ucsd.edu/data/amazon/
>
> 注释3：https://www.yelp.com/dataset/challenge
>
> 注释4：https://www.ratebeer.com/
>
> 注释5：对于 Beer，我们将Overall Rating的评分范围[4, 20]转换为[1, 5]。

![image-20211103161524401](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211103161524401.png)

【表 1】

#### 4.1.2 Baselines

在这里，我们将 CARP 与传统基线和最近提出的 SOTA 评分预测方法进行比较：(a) 仅利用评分的概率矩阵分解 PMF [23]；  (b) 使用评论的潜在主题和浅层嵌入学习模型，RBLT [26] 和 CMLE [37]；  (c) 使用评论的基于深度学习的解决方案，DeepCoNN [39]、D-Attn [24]、TransNet [3]、TARMF [19]、MPCN [27] 和 ANR [7]。

在这些方法中，D-Attn、TARMF、MPCN 和 ANR 都是识别评分预测的重要词。请注意，还有许多其他最先进的模型，例如 HFT [20]、EFM [38]、JMARS [8]、CDL [30]、ConvMF [15] 和 ALFM [6]。这些模型的表现已被此处比较的一个或多个基线超越。因此，为了节省空间，我们省略了进一步的比较。

#### 4.1.3 超参数

我们根据他们论文中报告的设置策略，应用网格搜索来调整所有方法的超参数。 所有方法的最终性能都报告了 5 次运行。 潜在维度大小从 $\{25, 50, 100, 150, 200, 300\}$ 优化。词嵌入是从头开始学习的。词嵌入的维度大小设置为 300（即 d = 300）。乐器、啤酒、办公产品和数字音乐的 batch 大小设置为 100。对于其他更大的数据集，batch 大小设置为 200。对于基于卷积的方法（包括 CARP、n  = 50）。

对于 CARP，窗口大小为 $c = 3$，对于Routing by Bi-Agreement ，迭代次数 $\tau$ 设置为 3，每个用户/物品的观点或 aspect 的数量设置为 5（即 M = 5），并且 $\lambda$ 为 0.5。对于模型训练，我们将 dropout 的保持概率设置为 0.9，将学习率设置为 0.001。 维度大小 $k$ 设置为 256 。

#### 4.1.4 评估指标

在这里，我们使用 MSE（参考等式 11）作为性能指标，该指标在许多相关的性能评估工作中被广泛采用 [19, 27, 32]。 统计显着性检验是通过执行学生 $t$ 检验进行的

### 4.2 性能评估

表 2 报告了七个数据集上所有方法的结果总结。首先，基于交互的方法 (PMF) 在所有七个数据集上始终产生最差的结果并不奇怪。这一观察结果与许多基于评论的作品 [15, 24, 39] 中所做的一致。

其次，在基于评论的基线中，七个数据集没有占主导地位的获胜者。  DeepCoNN 在不同数据集上的表现始终比其他解决方案差。 这是合理的，因为既没有使用词级注意力机制也没有使用 aspect 级注意力机制进行特征提取。相比之下，D-Attn 在大多数数据集中针对 DeepCoNN 获得了更好的性能，因为其使用了对偶词级注意机制。此外，TransNet 在所有数据集中的表现明显优于 DeepCoNN。 这一观察结果与先前的工作一致 [3, 27]。通过根据评分（即评分提升）重复每条评论，RBLT 可以从文本信息中精确提取语义主题。 在不同的数据集上实现了相对良好的性能（即与最佳基线相当），尤其是在较稀疏的数据集上。ANR 在三个数据集中表现最好，而 TransNet、D-Attn、TARMF 和 RBLT 在其余四个数据集中均优于其他数据集。 请注意，ANR 对来自 aspect 级别的评论的语义信息进行建模。这表明细粒度表示学习是更好地理解评级行为的有前途的途径。

第三，如表 2 所示，CARP 在七个数据集上始终保持最佳性能。值得强调的是，CARP 在 Beer 上获得了显着改进，而 Beer 是第二个最稀疏的数据集，评论信息最少（参考表格 1）。与最近提出的三个最先进的模型（即 TARMF、MPCN 和 ANR）相比，CARP 分别获得了高达 39.0%、9.7% 和 8.0% 的相对改进。总体而言，实验结果表明 CARP 可以有效地从评论中对评分行为进行建模以进行评级预测。

![image-20211103162309950](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211103162309950.png)

 【表 2】

### 4.3 对 CARP 的分析

我们进一步研究了参数设置（即 $\tau, M, \lambda$）对 CARP 在验证集上的性能的影响。在研究一个参数时，我们将其他参数固定为第 4.1 节中描述的值。请注意，并非所有数据集中的所有性能模式都如下所示。由于观察到了类似的模式并且性能规模大不相同，为了节省空间，我们省略了其中的一些。

#### 4.3.1 动态路由的影响

我们研究了 $\tau$ 在 CARP 动态路由中的影响。 表 4 报告了在 MSE  asepct 具有不同迭代次数的 CARP 的性能模式。

![image-20211103162213803](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211103162213803.png)

【表 4】

很明显，超过两次迭代会导致更好的预测准确度。通过执行 3 或 4 次迭代获得最佳性能。基于结果，我们在 CARP 中执行了 3 次迭代（即 $\tau = 3$）。我们还使用 [22] 中提出的标准协议路由 (RA) 进行实验。表 2 的最后一行报告了具有此设置（即 CARP-RA）的七个数据集的性能。 发现性能有不同程度的下降。 对于排在正胶囊中第 $i$ 个位置的每个逻辑单元 $g_{x,y}$，我们进一步检查相应的比率 $c_{pos,x,y}/c_{neg,x,y}$ 。 图 3(a) 报告了由 RBiA 和 RA 分别在 Musical 测试集上计算的正胶囊中每个位置的平均比率。我们可以看到，RBiA 计算出的逻辑单元的耦合系数更加 sharp。这表明 RBiA 更适合识别与用户评分高度相关的信息逻辑单元。

<img src="https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211103195317245.png" alt="image-20211103195317245" style="zoom: 50%;" />

【图 3】

在其他数据集中也观察到类似的模式。总体而言，结果表明所提出的 RBiA 通过抑制非信息逻辑单元的不利影响而具有优越性。

#### 4.3.2 $M$ 值的影响

$M$ 值分别指定为每个用户/物品提取的观点/ asepct 的数量。在这里，我们通过在 $\{3, 5, 7, 9\}$ 之间调整 $M$ 来报告 CARP 的性能模式。如表 3 所示，最佳 $M$ 值在整个数据集中不一致。 似乎在更多数据集中需要 $M = 5/7$。 鉴于性能变化很小，我们选择在我们的实验中使用 $M = 5$

![image-20211103161611108](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211103161611108.png)

【表 3】

#### 4.3.3 多任务学习的影响。

回忆公式 14，参数 $\lambda$ 控制 CARP 多任务学习设置中的权衡。图 3 (b) 通过在 [0.1, 1] 范围内以 0.1 的步长调整 $\lambda$ 来绘制三个数据集的性能模式。 当 $\lambda = 0$ 时，对如何预测最终评分没有监督。我们观察到，当 $\lambda$ 大约为 $0.5$ 时，始终可以达到最佳性能。 我们还观察到，当 $\lambda → 1$ 时，性能变得越来越差。这验证了在 CARP 中提出的多任务学习过程的积极好处。根据结果，我们在实验中将 λ 固定为 $0.5$，尽管这可能不是某些数据集的最佳设置。请注意，我们还在多任务学习过程中引入了互斥原理（参考等式 12 和 13）。如果没有这种互斥，CARP 会产生更差的性能，与 $\lambda = 1$ 的设置相当。

### 4.4 可解释能力分析

我们进一步检查 CARP 是否可以发现正确的原因及其影响来解释评分行为。

表 5 显示了这些句子和 CARP 提供的辅助信息。回想一下，CARP 编码了上下文信息来表示每个单词。为了更好地可视化一个观点（一个 aspect），我们检索 top-$K$ 个短语，其权重是卷积窗口中组成词的权重之和（即等式 2 中的 $attn_{u,x,j}$）。最后，我们选择包含这些信息短语的句子来代表相应的观点/ asepct 。 在这里，我们选择 $K = 30。$我们从两个数据集中随机抽取三个用户-物品对。具有相同用户但不同物品的前两对来自 Office Products。 最后一个是从 Musical Instruments 中挑选出来的。对于评分较高的一对，我们分别列出正面和负面情绪胶囊提取的 top-2 和 top-1 逻辑单元，反之亦然。请注意，鉴于我们的 $M$ 是全局参数，提取的观点（或 asepct ）可以覆盖多个子视点（或子 asepct ）。此外，据观察，某些短语会出现在两个观点或 asepct 中。这是合理的，因为观点或 asepct 是由不同短语组合而成的高级概念，其中一些仅具有一般语义。我们选择每个逻辑单元中信息量最大的一两个句子。信息性短语以橙色突出显示。上下文中的停用词 (stop words) 也被突出显示以便更好地理解。蓝色表示该短语与多个观点/ asepct 相关联。我们还通过最大归一化变换原始 $r_{s,u,i}$ 值以简化解释，因为最终评分是通过非线性迁移估计的（参考等式 10）。作为参考，我们在目标用户-物品评论中显示与这些逻辑单元匹配良好的部分，分别用红色和绿色下划线表示正面和负面情绪胶囊。

![image-20211103195242953](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211103195242953.png)

【表 5】

#### 4.4.1 例 1

第一对中的物品是一个 Smead MO File Box，用户评分较低（即 2.0）。第一个逻辑单元表明用户更喜欢金属质感和高品质。但是，相关的 aspect 表明，该物品不能容纳重物。第二个逻辑单元直接表明用户是一个节俭的人，该物品显然很贵。对于此物品，用户其实也有喜欢的地方。第三个逻辑单元表明用户喜欢灵活性和通用性，这确实体现在物品文档中。然而，这是一个微弱的积极影响。请注意，目标评论中确实提到了逻辑单元 $g_{1,5}$ 和 $g_{5,3}$ 所表达的因果关系。

#### 4.4.2 例2

与第一对相比，第二对说明了同一用户对具有高评分（即 4.0）的 Post-it Big Pads 的原因和影响。 第一个和第二个逻辑单元表明某些信息需求（即有吸引力的外观和发布东西很方便）与物品很好地匹配。用户写的目标评论也很好的涵盖了这两个逻辑单元。 第三个逻辑单元并不容易解释。然而，在这个逻辑单元之下确实存在一些暗示。如第一个例子中的第二个逻辑单元所示，该用户提到金属质感和高品质（两个逻辑单元的相同观点），表明她也喜欢坚固的、不易损的东西。 同时，便利贴确实没有这个属性。负面胶囊的输出长度较短（即 0.293）表明该原因具有较弱的负面影响，这也被用户的整体高评价所证实。

#### 4.4.3 例3

这个例子来自Musical Instruments。 第一个逻辑单元显示用户-物品对就节省空间达成一致。类似地，第二个逻辑单元表明用户持有 cost-effective 的观点，这与该物品的高性价比 (high cost performance ) 很好地匹配。这个逻辑单元在目标评论中也很匹配。 第三个逻辑单元涉及一点推理。 很明显，用户更喜欢外观酷的东西。 相比之下，根据评论，该物品看起来无趣。 高评分表明该逻辑单元不重要。这种效应也被 CARP 以相对较低的 $r_{neg,u,i}$（即 0.753）和较小的向量长度（即 0.295）捕获。总体而言，我们的结果表明，CARP 在评分预测方面具有优势，并有助于在更精细的粒度级别上解释原因和结果。

## 5 结论

所提出的基于胶囊网络的推荐和解释模型可以看作是推理特定类型人类活动的一步。我们广泛的实验表明，通过在细粒度级别对原因和影响进行建模，可以获得更好的推荐性能和理解。实际上，根据用户观点、物品 aspect 和情绪来推理评分行为可以在电子商务中进一步受益，包括跨域推荐、用户画像和面向用户的评论总结。我们将在未来研究这些可能性。

