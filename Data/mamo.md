# MAMO: Memory-Augmented Meta-Optimization for Cold-start Recommendation

## 摘要

大多数当前推荐系统的共同挑战是冷启动问题。 由于缺乏用户-物品交互，微调的推荐系统无法处理新用户或新物品的情况。 最近，一些工作将元优化 (meta-optimization) 思想引入到推荐场景中，即仅通过一些过去的交互物品来预测用户偏好。核心思想是为所有用户学习一个全局共享初始化参数，然后分别学习每个用户的局部参数。 然而，大多数基于元学习的推荐方法采用与模型无关的元学习进行参数初始化，其中全局共享参数可能会将模型引导到某些用户的局部最优。 在本文中，我们设计了两个记忆 (memory) 矩阵，可以存储特定于任务 (task-specific) 的记忆和特定于特征 (feature-specific) 的记忆。 具体而言，特定于特征的记忆用于引导具有个性化参数初始化的模型，而任务特定记忆用于引导模型快速预测用户偏好。 我们采用元优化方法来优化所提出的方法。 我们在两个广泛使用的推荐数据集上测试模型并考虑四种冷启动情况。实验结果表明了所提出方法的有效性。

## 1 引言

个性化推荐系统在 Web 和移动应用程序中扮演着越来越重要的角色。尽管基于传统矩阵分解的推荐方法 [4] 或最新的基于深度学习的技术 [33] 取得了成功，但大多数推荐方法的共同挑战是冷启动问题 [28]。 由于缺乏用户-物品交互，利用这种交互的推荐方法无法处理存在新用户或物品的情况，对应于用户冷启动和物品冷启动问题。

解决冷启动问题的传统方法是在推荐系统中利用辅助信息，例如基于内容的推荐系统 [21, 27] 和跨域推荐系统 [16, 25]。例如，为了解决物品冷启动问题，[27] 提出了一种混合模型，其中物品特征通过堆叠降噪自动编码器从物品描述中学习，并进一步组合成协同过滤模型 timeSVD++。 在[25]中，作者提出了一种跨域潜在特征映射模型，其中应用基于邻域的跨域潜在特征映射方法来学习每个冷启动用户的特征映射函数。 然而，这种方法的主要局限性在于，学习的模型可能会为内容相似的用户推荐相同的物品，从而忽视个人兴趣。

受近期小样本学习 [26] 工作的启发，元学习 [24] 已被引入推荐系统以解决冷启动问题，即仅通过几个过去的交互物品来预测用户的偏好。 当前大多数基于元学习的推荐系统 [5, 15, 34] 采用基于优化的算法，例如与模型无关的元学习 (MAML) [11]，因为它们在新任务的学习配置初始化方面表现良好。通常，对用户的推荐被视为学习任务。 核心思想是学习一个全局参数来初始化个性化推荐模型的参数。 个性化参数将在局部更新以了解特定用户的偏好，并通过最小化用户之间训练任务的损失来更新全局参数。 然后，学习到的全局参数用于指导新用户的模型设置。例如，[15] 使用几个全连接的神经网络作为推荐模型。 他们首先从用户和物品画像中学习用户和物品嵌入 (embedding) ，然后将它们输入推荐模型以获得预测。 他们定义了两组全局参数：学习嵌入中的参数和推荐模型中的参数。 他们在局部更新推荐模型以进行个性化推荐，并全局更新两组参数以用于新用户的初始化。 [8] 还构建了一个深度神经网络作为推荐模型。 他们定义了一个全局参数来初始化推荐模型，然后通过引入更新和停止控制器来局部更新模型参数。

上述方法已被证明，在冷启动场景中应用元优化很有希望表现出和在热启动场景中不相上下的性能。但是，它们具有以下限制。 它们大多建立在 MAML 算法及其变体之上，这些算法在应对数据稀疏性方面非常强大，但存在不稳定、收敛速度慢、泛化能力弱等各种问题。 特别是，与训练集中的大多数用户相比，它们在处理显示不同梯度下降方向的用户时，经常会遇到梯度退化 (gradient degradation) ，最终导致局部最优。为了解决这个问题，我们提出了用于冷启动推荐的记忆增强元优化（MAMO）。具体来说，

(1) 为了解决局部最优问题，我们设计了一个特定于特征的记忆，以在初始化模型参数时提供个性化的偏置项。 具体来说，特征特定记忆包括两个记忆矩阵：一个存储 (store) 用户画像记忆以提供可检索 (retrievable) 的注意力值，另一个缓存 (cache) 根据可检索的注意力值读取的先前训练集的快速梯度。 

(2)我们进一步设计了一个特定于任务的记忆立方体，即用户偏好记忆，以学习捕捉不同物品上共享的潜在用户偏好共性 (potential user preference commonality)。 它被用作推荐模型的快速权重，以减轻对存储神经活动模式 (neural activity patterns) 副本的需求。

(3) 在两个广泛使用的数据集上进行的大量实验表明，MAMO 与最先进的技术相比表现出色。 该代码可公开用于复现^1^ (reproduction)。

>  注释1：https://github.com/dongmanqing/Code-for-MAMO

## 2 所提出的方法

### 2.1 总览

#### 2.1.1 问题定义

我们将给用户的推荐视为一项任务。 给定一个用户 $𝑢$ 具有画像 $𝑝_𝑢$ 和评分物品 $I^𝑆_𝑢$ ，其中每个物品 $𝑖$ 与描述文件 $𝑝_𝑖$ 和相应的评分 $𝑦^𝑆_{𝑢,i}$ 相关联，我们的目标是预测用户对新物品 $ 𝑖 \in I^𝑄_𝑢$。 这里，$𝑆$ 代表支持集 (support set)，$𝑄$ 代表查询集 (query set) 。

#### 2.1.2 动机 (Motivation)

大多数现有的基于元学习的推荐技术都试图学习一个元全局参数 $\phi$ 来指导模型初始化 $R_\theta$ ，即 $\theta \leftarrow \phi$，其中 $\phi$ 在训练集中的所有用户中学习。 它提供了一个统一的参数初始化来管理训练好的推荐模型来预测新用户。 全局参数 $\phi$ 在所有用户之间统一工作，因此可能不足以辨别各种用户模式之间的内在差异，从而导致泛化能力较差。 此外，该模型可能倾向于陷入局部最优并遇到梯度退化。 我们提出了一种自适应元学习推荐模型，即记忆增强元优化（MAMO），以通过学习多级别 (multi-level) 的个性化模型参数来改进模型的稳定性、泛化性和计算成本，而不是学习模型参数的单个初始化。

#### 2.1.3 模型架构

所提出的模型包括两部分：用于预测用户偏好的推荐模型和用于初始化推荐模型参数的记忆增强元优化学习器。 推荐模型 $R_\theta(𝑝_𝑢, 𝑝_𝑖)$ 预测推荐分数，其中模型参数 $\Theta = \{\theta_𝑢, \theta_𝑖 , \theta_𝑟 \}$ 将局部地 (locally) 更新，以提供个性化推荐。 元学习器 (meta-learner)，它包括全局参数 $Φ = \{\phi_𝑢, \phi_𝑖 , \phi_𝑟 \}$ 和记忆 $M=\{M_U, M_P, M_{U,I} \}$ ，在用户的训练过程中对用户 $𝑢 \in 𝑈^{𝑡𝑟𝑎𝑖𝑛}$ 会全局地 (globally) 更新，学习到的元学习器进一步用于为新用户初始化推荐模型 $𝑢 \in 𝑈^{test}$ 。

![image-20211023162036627](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211023162036627.png)

【图 1】

### 2.2 推荐模型

与之前的许多工作类似，我们假设用户偏好来自其个人信息的复杂组合，例如用户资料、用户评分记录和物品资料

#### 2.2.1 嵌入 (embedding)：$p_u \rightarrow e_u, p_i \rightarrow e_i$ 

出于以下考虑，我们使用用户画像 $𝑝_𝑢$ 来表示初始用户偏好。
首先，用户画像通常包括一般信息，例如年龄组和位置。 在冷启动场景中，只有有限的用户-物品交互记录，这将为推荐模型提供潜在的用户偏好。 其次，传统的 one-hot 用户表示（通过唯一 id）强烈依赖于协同过滤技术。 微调的模型很难适应新用户。 类似地，我们使用 $𝑝_𝑖$ 表示用于学习物品嵌入的物品画像。

要从 $𝑝_𝑢 \in \mathbb R ^{𝑑_𝑢}$ 和 $𝑝_i \in \mathbb R ^{𝑑_i}$ 中学习用户和物品嵌入向量 $e_u \in \mathbb R^{d_e}$ 和 $e_i \in \mathbb R^{d_u}$ ，最简单的神经网络方式是构建多层神经网络，即：
$$
e_u = f_{\theta_u}(p_u),\ e_i=f_{\theta_i}(p_i)
\tag1
$$
其中 $𝑑_𝑒$ 是嵌入维度大小；  $𝑓$ 表示全连接层；  $𝑑_𝑢$ 和 $𝑑_𝑖$ 分别代表用户画像向量和物品画像向量的维度；  $\theta_𝑢$ 和 $\theta_𝑖$ 分别是用于学习用户和物品嵌入的全连接层的参数。 我们将在本文的其余部分省略类似的符号

#### 2.2.2 推荐：$(e_u,e_i) \rightarrow y_{u,i}$

给定用户嵌入 $𝑒_𝑢$，以及 $𝑖 \in I^𝑄_𝑢$ 的评分物品嵌入 $𝑒_𝑖$ 的列表，我们通过以下方式得到每个物品的偏好分数 $𝑦_{𝑢,𝑖}$ 的预测：
$$
\hat y_{u,i} = f_{\theta_r}(e_u,e_i) = {\rm FC}_{\theta_r}(M_{u,I}\cdot [e_u,e_i])
\tag2
$$
其中 $[𝑒_𝑢, 𝑒_𝑖]$ 是用户嵌入和物品嵌入的拼接 (concatenation)，$\rm FC$ 表示全连接层。
$𝑀_{𝑢,𝐼} \in \mathbb R^{𝑑_𝑒×2𝑑_𝑒}$ 是一个矩阵，其中包含用户 $𝑢$ 的推荐模型的快速权重 (fast weights)，它是从特定于任务的记忆 $M_{U,I}$ 中提取的。 用户 $𝑢$ 的特定于任务的记忆 $𝑀_{𝑢,𝐼} $ 将局部地更新（即在用户 $𝑢$ 的支持集上学习期间），以进行个性化推荐。 我们将在后面的部分中介绍有关特定于任务的记忆的更多详细信息。

### 2.3 记忆增强元优化

#### 2.3.1 特定于特征的记忆: $(p_u, M_U, M_P) \rightarrow b_u$

回想一下，用于提取用户和物品嵌入的参数是 $\theta_𝑢$ 和 $\theta_𝑖$，传统的元优化方法将学习全局参数 $\phi_𝑢 $和 $\phi_𝑖 $进行初始化，即 $\theta_𝑢 \leftarrow \phi_𝑢, \theta_i \leftarrow \phi_𝑖 $ 。在这里，为了解决单一初始化问题，我们引入了特定于特征的记忆，即用户嵌入记忆 $𝑀_𝑈$ 和画像记忆 $𝑀_𝑃$ ，以帮助模型初始化个性化参数 $\theta_𝑢$。画像记忆 $𝑀_𝑃$ 存储与用户画像 $𝑝_𝑢$ 相关的信息，以提供检索注意力值 $𝑎_𝑢$。 检索注意力值用于从用户嵌入记忆 $𝑀_𝑈$ 中提取信息，其中 $𝑀_𝑈$  的每一行保持相应的快速梯度（或偏置项）。 一起，这两个记忆矩阵将有助于在初始化 $\theta_𝑢$ 时生成个性化的偏置项 $𝑏_𝑢$，即 $\theta_𝑢 ← \phi_𝑢 − \tau𝑏_𝑢$。 这里偏差项 $𝑏_𝑢$ 可以看作是一个个性化的初始化参数，用于引导全局参数 $\phi_𝑢$ 快速适应用户 $u$ 的情况； $\tau$ 是一个超参数，用于控制初始化 $\theta$ 时考虑多少偏差项。

具体来说，给定一个用户画像 $𝑝_𝑢$，画像记忆 $𝑀_𝑃 \in \mathbb R^{𝐾\times 𝑑_𝑢}$ 将通过以下方式计算注意力值 $𝑎_𝑢 \in \mathbb R^𝐾$ 
$$
a_u = {\rm attention}(p_u, M_p)
\tag3
$$
其中 $\rm attention$ 函数计算用户档案和用户档案记忆之间的余弦相似度，然后通过 softmax 函数进行归一化。 维度 𝐾 表示用户偏好类型的数量，这是在训练过程之前预定义的数字。 我们通过以下方式获得个性化偏差项 $𝑏_𝑢$
$$
b_u = a_u^T M_U
\tag4
$$
其中 $𝑀_𝑈 \in \mathbb R^{𝐾 \times \{𝑑_{𝜃_𝑢} \}}$ 存储快速梯度的记忆。请注意，用户嵌入模型可能包含多个神经层和多个参数，这意味着 $𝑀_𝑈$ 不是数值矩阵，而是存储所有与用户嵌入层中的参数形状相同的快速梯度，因此这里 $𝑑_{𝜃_𝑢}$ 表示用户嵌入层中参数的维度。

在训练过程之前，两个记忆矩阵被随机初始化，并会在训练过程中更新。具体来说，画像记忆通过以下方式更新：
$$
M_P = \alpha \cdot (a_u p_u^T) + (1-\alpha)M_P
\tag5
$$
其中 $(𝑎_𝑢 𝑝^⊤_𝑢)$ 是 $𝑎_𝑢$ 和 $𝑝_𝑢$ 的叉积 (cross product)，$\alpha$ 是一个超参数，用于控制添加多少新的画像信息。
这里我们在添加新信息时添加了一个注意力掩膜 (mask) $𝑎_𝑢$，以便新的画像信息将被专注地添加到记忆矩阵中。 类似地，参数记忆 $𝑀_𝑈$ 将被更新为
$$
M_U = \beta \cdot (a_u \nabla_{\theta_u} ({\cal L}(\hat y_{u,i}, y_{u,i})))
+(1- \beta )M_U
\tag6
$$
其中 ${\cal L}(\hat y_{u,i}, y_{u,i})$ 表示训练损失，而 $\beta$ 是控制保留多少新信息的超参数

#### 2.3.2 特定于任务的记忆 $(a_u,M_{U,I}) \rightarrow M_{u,I}$

用户偏好矩阵 $𝑀_{𝑢,𝐼} \in \mathbb R^{𝑑_𝑒×2𝑑_𝑒}$  用作快速权重或来自用户和物品嵌入的推荐模型的变换矩阵（参见等式(2)），从记忆立方体 $𝑀_{U,𝐼} \in \mathbb R^{K\times 𝑑_𝑒\times 2𝑑_𝑒}$ 中提取，其中 𝐾 是表示用户偏好类型数量的特定于特征的记忆的维度的相同符号。类似于遵循神经图灵机（NTM）[13] 思想的特定于特征的记忆，记忆立方体 $𝑀_{U,I}$ 有一个读头来检索记忆和一个写头来更新记忆。类似地，我们带注意力地从 $𝑀_{𝑈,𝐼}$ 中检索偏好矩阵 $𝑀_{u,I}$
$$
M_{u,I} = a_u^T \cdot M_{U,I}
\tag7
$$
其中 $𝑎_𝑢 \in \mathbb R^𝐾$ 是从等式 3 中学习的。写头将在支持集上学习后将更新的个人偏好记忆矩阵 $𝑀_{𝑢,I}$ 写入 $𝑀_{𝑈,𝐼}$。
$$
M_{U,I} = \gamma \cdot (a_u \otimes M_{u,I}) + (1-\gamma)M_{U,I}
\tag8
$$
其中 $\otimes$ 表示张量积，$\gamma$ 是一个超参数，用于控制添加多少新的偏好信息。

#### 2.3.3 局部更新

传统上，神经网络的参数是通过从统计分布中随机抽样来初始化的。 给定足够的训练数据，随机初始化的参数通常可以收敛到一个好的局部最优，但可能需要很长时间[8]。 在冷启动场景下，随机初始化结合有限的训练数据会导致严重的过拟合，这使得训练好的推荐模型不能很好地泛化。 受元训练[15]最近工作的启发，我们从全局初始值初始化推荐模型的参数。

在训练过程开始时，我们随机初始化全局参数，即 $\phi_𝑢、\phi_𝑖、\phi_𝑟、𝑀_𝑈、𝑀_𝑃、𝑀_{U,I}$。 对于每个用户 $𝑢 \in 𝑈^{𝑡𝑟𝑎𝑖𝑛}$，我们有支持集和查询集。 在局部学习阶段（即在支持集上学习），我们通过以下方式初始化本地推荐参数：
$$
\theta_u \leftarrow \phi_u - \tau b_u
\tag9
$$

$$
\theta_i \leftarrow \phi_i, \ \theta_r \leftarrow \phi_r
\tag{10}
$$

其中 $𝑏_𝑢$ 是通过等式（3-4）获得的。 然后我们通过等式（7）获得特定于任务的记忆矩阵 $𝑀_{𝑢,𝐼}$。 物品 $𝑖 ∈ I^𝑆_𝑢$ 的评分预测基于等式（2）。局部训练中的优化目标是最小化单个用户的推荐损失，即通过最小化预测损失 ${\cal L}(y_{u,i}, \hat y_{u,i})$  来更新局部参数。 因此，本地参数将被更新为
$$
\theta_* \leftarrow \theta_*- \rho \nabla_{\theta_*} {\cal L}(y_{u,i}, \hat y_{u,i})
\tag{11}
$$
其中 $∗$ 可以是 $𝑖$、$𝑢$ 或 $𝑟$；  $\rho$ 是更新局部参数的学习率。 偏好矩阵 $𝑀_{𝑢,𝐼}$ 也将通过反向传播在局部更新。

#### 2.3.4 全局更新

元优化的目的是最小化本地查询集 $𝑖 \in I^𝑄_𝑢$ 对于 $𝑢 \in 𝑈^{𝑡𝑟𝑎𝑖𝑛}$ 的预期损失。这里，元学习器的参数包括：共享初始参数$\phi_𝑢$、$\phi_𝑖$和 $\phi_𝑟$； 特定于特征的记忆，即画像记忆 $𝑀_𝑃$ 和用户嵌入记忆 $𝑀_𝑈$；和特定于任务的记忆  $𝑀_{𝑈,𝐼}$ 。与元测试 (meta-testing) 损失相关的梯度，我们称之为元梯度，可以通过反向传播来计算。 元梯度可能涉及高阶导数，当神经网络的深度很深时，计算这些导数很昂贵。因此，MAML[22] 采用一步 (one-step) 梯度下降进行元优化。 我们采取类似的想法，在支持集上进行局部训练后，我们根据查询集上的损失更新全局参数。

假设推荐模型表示为 $R_𝜃$ ，结合了用户 $𝑢$ 的任务特定记忆 $𝑀_{𝑢,𝐼}$，其中 $\theta = \{\theta_𝑢, \theta_𝑖,\theta_𝑟\}$。
在支持集上进行局部训练后，我们得到了具有更新后的参数 $\hat \theta$ 的模型 $R_{\hat \theta}$。 我们的目标是最小化用户 $u \in 𝑈^{𝑡𝑟𝑎𝑖𝑛}$ 在 $𝑖 \in I^𝑄_𝑢$ 的查询集上的训练损失。 然后，全局参数更新为
$$
\phi_* \leftarrow \phi_* - \lambda \sum_{u \in U^{train}}\sum_{i \in I^Q_u} 
\nabla {\cal L}(R_{\hat \theta_*})
\tag{12}
$$
同时，特定于特征的记忆 $𝑀_𝑃$和 $𝑀_𝑈$ 将通过等式（5）和（6）更新； 特定于任务的记忆 $𝑀_{𝑈,𝐼}$ 将通过等式（8）更新。 训练过程伪代码见算法1。

![image-20211023171037451](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211023171037451.png)

【算法 1】



## 4 相关工作

### 4.1 推荐系统中的冷启动问题

对于推荐系统来说，准确地向用户推荐物品仍然是一个棘手而重要的问题。 当前的出版物[20]中已经提供了解决这个问题的一些解决方案，包括第二领域知识转移[16]、辅助和上下文信息[21、31]、主动学习 (active learning)[35]和深度学习[9]。

通常，据报告，信息越多，推荐结果越好。[19] 将带有聚类 (clusters) 的矩阵分解添加到跨域推荐中。 同样，[16]根据偏最小二乘回归（PLSR）分析提出了跨域推荐的创新模型。PLSR-CrossRec 和 PLSR-Latent 都可以用于源域的评分，以更好地预测冷启动用户的评分。除了利用其他领域的辅助信息外，一些研究人员在处理冷启动问题时，将具有代表性的 (representative) 物品内容作为辅助信息来学习具有代表性的潜在因子。 根据隐式反馈，[21] 提出了一种名为 visual-CLiMF 的方法来学习冷启动视频的具有代表性的潜在因子，其中物品的情感 aspect 被纳入视频内容的潜在因素表示中。 为了在进一步的潜在特征中更好地使用内容特征，[7] 提出了一种用于冷启动推荐的下一首歌曲推荐系统，通过在音频特征和物品潜在空间内映射学习和更新。 此外，主动学习已经找到了解决用户 [10] 和物品 [1] 中的用户冷启动问题的方法。  [35]将主动学习方法与物品的属性信息相结合来处理物品中的冷启动问题。
最近的工作利用了深度学习 [9, 27, 32]。  [18] 提出了一种面向多重交互的服务推荐方法（MISR），将不同的交互融合到一个深度神经网络中来搜索潜在信息，以便更好地处理新用户。  [27] 提出了一种混合推荐模型，通过深度学习神经网络研究物品的内容特征，然后将其应用于 timeSVD++ 协同过滤模型

### 4.2 元学习与推荐系统

