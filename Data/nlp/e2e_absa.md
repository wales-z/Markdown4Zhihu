# A Unified Model for Opinion Target Extraction and Target Sentiment Prediction

## 摘要

基于目标的情感分析包括意见目标 (opinion target) 提取和目标情感分类。 然而，大多数现有作品通常只研究这两个子任务之一，这阻碍了它们的实际应用。 本文旨在以端到端的方式解决基于目标的情感分析的完整任务，并提出了一种应用统一标记方案的新颖统一模型。 我们的框架涉及两个堆叠的循环神经网络：上层预测统一标签以产生主要基于目标的情感分析的最终输出结果； 下层执行辅助目标边界预测，旨在引导上层网络提高主要任务的性能。 为了探索任务间的依赖性，我们建议对从目标边界到目标情感极性的约束转换进行明确建模。 我们还提出通过一个门机制来保持意见目标中的情感一致性，该机制对当前词和前一个词的特征之间的关系进行建模。 我们对三个基准数据集进行了广泛的实验，我们的框架取得了始终如一的卓越结果。

## 1 引言

基于目标的情感分析 (TBSA) 旨在检测句子中明确提及的意见目标，并预测意见目标的情感极性 (Liu 2012; Pontiki 2014)。 例如，在“USB3外设明显比Thunder Bolt的便宜”这句话中，用户提到了“USB3外设”和“ThunderBolt的”两个意见目标，并表达了对 第一个的积极情感，以及对第二个的负面情感。

传统上，该任务可以分解为两个子任务，即意见目标提取和目标情感分类。 意见目标提取的目标是检测文本中提到的意见目标，并且已经被广泛研究。 第二个子任务，即目标情感分类，作用是所提取目标的有用性 (usefulness) 的乘数，因为它可以预测给定意见目标的情感极性。 这个子任务近年来也受到了很多关注。 然而，大多数解决第二个子任务的现有方法都假设目标是给定的，这限制了它们的实际使用。 综上所述，上述所有工作都旨在解决其中一个子任务。 为了在实际环境中应用这些现有方法，即不仅要提取目标，还要预测目标情绪，一种典型的方法是将两个子任务的方法流水线化。

正如在其他一些任务中所观察到的，如果两个子任务具有强耦合（例如，NER 和关系提取），则一个更集成的模型通常比流水线解决方案更有效。 对于 TBSA 任务，之前的研究人员尝试了两种方法来获得更集成的解决方案。 一种方法是联合训练两个子任务的模型，它利用一组目标边界标签（例如 B、I、E、S 和 O）和一组情感标签（例如 POS、NEG  , NEU)。 表 1 的“联合”行给出了这种方法中标记方案的示例。另一种方法是完全消除两个子任务的边界，它利用一组专门设计的标签（我们称之为“统一标签方案”），即 B-{POS, NEG, NEU}, I-{  POS, NEG, NEU}, E-{POS, NEG, NEU}, S-{POS, NEG, NEU}, 表示意见目标的开始 (beginning)、内部 (inside)、结束 (end) 和单个词 (single-word) ，分别带有积极、消极或中性情感，O 表示空情感。 表 1 中的“unified”行给出了一个示例。不幸的是，这些最初的尝试并没有产生一个可以胜过流水线方法的集成度更高的模型。

![image-20211007150026543](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211007150026543.png)

【表1】

尽管解决完整的 TBSA 任务的重要性仍然很重要，但现有研究相对较少，他们的发现在一定程度上劝退了 (discourage) 其他研究人员进行进一步的探索。 然而，我们认为应该努力探索解决这个任务的更集成的模型，因为它的两个子任务高度耦合在一起，一个更集成的模型的潜力是有希望的。

在本文中，我们研究了 TBSA 的完整任务并设计了一个新颖的统一框架来以端到端的方式处理它。 此框架涉及两个堆叠的循环神经网络 (RNN)。 上层基于统一的标注方案产生TBSA任务的最终标注结果。 下层执行目标边界的辅助预测，目的是指导和提供信息给上层 RNN。 这种设计是基于如下观察：在统一标记方案下，跨度 (span) 信息与边界标记方案下的完全相同。 参考表1中的例子，如果一个词在边界方案下的目标提及的开头，即有标签B，它也应该在统一方案下的开头，即有标签 B-POS。 为了探索这种方案间 (inter-scheme) 标签依赖性，我们建议使用来自辅助任务的边界预测来指导上层 RNN 对完整 TBSA 任务的预测，对应于下层 RNN。 具体来说，我们设计了一个组件将依赖关系编码成一个转换矩阵，并使用该矩阵将边界预测的概率分布映射到 TBSA 任务的统一标签空间。 然后，我们确定获得的基于边界的概率分数在标记决策中的比例，并将它们与来自上层 RNN 的概率分数合并以进行最终预测

我们还建议基于简单的门机制来保持同一目标中单个词的情感的一致性。 门机制旨在明确合并 (consolidate) 当前词和前一个词的特征。 由于这里的门和上面的转换矩阵都需要进行可靠的边界预测才能很好地执行，因此在较低的 RNN 中提高这种预测的可靠性应该对完整的 TBSA 任务有用。 因此，我们引入了另一个组件来估计一个词成为目标词的可能性。 请注意，根据任务的定义，意见目标应始终与意见词同时出现，因此，接近意见词的词更有可能是目标词，基于此假设我们获得了额外的细化边界信息的监督信号。

在实验中，我们的框架在几个基准数据集上优于最先进的方法和最强的序列标记器。 我们进行了详细的消融研究，以定量证明设计组件的有效性。 通过一些案例分析，我们展示了我们的框架如何在设计的组件的帮助下处理一些困难的案例

## 2 我们提出的框架

### 2.1 任务定义

我们将完整的基于目标的情感分析 (TBSA) 任务制定为序列标记问题，并采用统一的标记方案：

$\cal Y^S =$ {B-POS, I-POS, E-POS, S-POS, B-NEG, I-NEG, E-NEG, S-NEG, B-NEU, I-NEU, E-NEU, S-NEU, O}  。 除 O 外，每个标签包含两部分标签信息：目标的边界和目标情感。例如，B-POS 表示积极目标的开始，S-NEG 表示单个词的消极意见目标。 对于给定的输入序列 ${\rm X} = \{x_1,..., x_T \}$， 长度为 $T$，我们的目标是预测标签序列 ${\rm Y}^{\cal S} = \{y^{\cal S}_1 , .  .  .  , y^{\cal S}_T \}$，其中 $y^{\cal S}_i \in \cal Y^S$。

### 2.2 模型描述

#### 2.2.1 总览

如图 1 所示，在两个带有 LSTM 单元的堆叠 RNN 的顶部，我们的框架设计了三个量身定制的组件，用标注进行了详细描述，以探索 TBSA 任务中的三个重要直觉。 具体来说，上层 ${\rm LSTM}^{\cal S}$ 用于完整的 TBSA 任务，预测统一标签作为输出，下层 ${\rm LSTM}^{\cal T}$ 用于辅助任务，预测目标提及的边界标签。  ${\rm LSTM}^{\cal T}$ 的边界预测用于指导 ${\rm LSTM}^{\cal S}$对完整任务的统一标签进行更好的预测。

![image-20211007151909996](https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211007151909996.png)

三个关键组件被命名为边界指导 (Boundary Guidance, BG) 组件、情感一致性 (Sentiment Consistency, SC) 组件和意见增强 (Opinion-Enhanced, OE) 目标词检测组件。 BG组件利用辅助任务提供的边界信息来指导 ${\rm LSTM}^{\cal S}$ 更准确地预测统一标签。  SC 组件具有门机制，可以将前一个词的特征显式地整合到当前预测中，旨在保持多词意见目标内的情感一致性。 为了提供更高质量的边界信息，OE组件遵循“意见目标和意见词总是同时出现”的观察，执行另一个辅助二分类任务来确定当前词是否是目标词

#### 2.2.2 有目标边界指导的TBSA 

我们使用带有 softmax 解码层的  ${\rm LSTM}^{\cal S}$ 来预测标签序列。 我们观察到，边界标签可以为统一标签预测提供重要线索。 例如，如果当前边界标签是B，表示意见目标的开始，那么对应的统一标签只能是B-POS、B-NEG或B-NEU。 因此，我们为目标边界预测引入了一个额外的网络 ${\rm LSTM}^{\cal T}$，其中有效标签集 $\cal Y^T$ 是 {B, I, E, S, O}。 我们将这两个 LSTM 层连接起来，以便 ${\rm LSTM}^{\cal T}$生成的隐藏表示可以作为指导信息直接馈送到 ${\rm LSTM}^{\cal S}$。 具体来说，它们在第 $t$ 个时间步 $(t \in [1, T])$ 的隐藏表示 $h^{\cal T}_t \in \mathbb R^{dim^{\cal T}_h}$ 和 $h^{\cal S}_t \in \mathbb R^{dim^{\cal S}_h}$ 计算如下：

<img src="https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211007154837969.png" alt="image-20211007154837969" style="zoom:50%;" />

边界上的标签的概率分数 $z^{\cal T}_t ∈ \mathbb R^{|\cal Y^T|}$ 由一个全连接的 softmax 层计算：
$$
z^{\cal T}_t = \bold p (y_t^{\cal T}| x_t) = {\rm Softmax}(\bold W^{\cal T} h_t^{\cal T})
\tag2
$$
其中 Softmax 表示 softmax 激活函数，$\bold W^{\cal T}$ 是模型参数。 类似地，统一标签 $z^{\cal S}_t ∈ \mathbb R^{|\cal Y^S|}$ 上的分数的计算如下：
$$
z^{\cal S}_t = \bold p (y_t^{\cal S}| h_t^{\cal T}) = {\rm Softmax}(\bold W^{\cal S} h_t^{\cal S})
\tag3
$$
如上所述，边界信息应该有助于提高 ${\rm LSTM}^{\cal S}$ 的性能。  (Zhang、Zhang 和 Vo 2015) 通过在 CRF 模型的解码步骤中添加硬边界约束来合并此类边界信息。 然而，他们的预测结果并不乐观。 一个原因是他们的模型采用了一种硬约束，它容易传播边界检测任务的标记器的错误，从而降低了 TBSA 标记器的性能。 与施加硬约束的方式不同，我们提出的 BG 组件可以通过边界指导转换 (boundary guided transition) 吸收边界信息，并根据目标边界标记器的置信度自动确定其在最终标记决策中的比例。 首先，BG 组件将约束编码为转换矩阵 $\bold W^{tr} \in \mathbb R ^{|\cal Y^T|\times |\cal Y^S|}$ 。 由于我们没有关于边界标签和统一标签之间的转换概率的先验知识，我们最初将它们设置为如下：
$$
W^{tr}_{i,j}=\begin{cases}
\frac {1}{|\cal B_i|}, \ \ \ {\rm if} \ j\in \cal B_i \\
0, \ \ \ \ \ \ \ \rm otherwise
\end{cases}
\tag4
$$
其中 $\cal B_i$ 是与边界标签 $i$ 一致的有效统一标签集合。 在这个转换矩阵中，一个非零元素，例如，$\bold W^{tr}_{\rm B,B-POS}$，表示给定边界标签的统一标签的概率，而一个零元素，例如，$\bold W^{tr}_{\rm B,I-NEG}$，表明统一标签的概率无法通过此转换推断出标记。 对约束进行编码后，下一步是用边界信息指导统一标签预测。 我们通过将边界标签 $z^{\cal T}_t$ 的概率分数映射到统一标签空间，直接将这些信息传播到 TBSA 标注器。 基于转换的情感分数 $z^{\cal S'}_t \in \mathbb R^{|\cal Y^S|}$ 的计算如下：
$$
z^{\cal S'}_t = (\bold W^{tr})^{\rm T} z^{\cal T}_t
\tag5
$$
其中转换操作等价于转换矩阵 $\bold W^{tr}$ 中行向量的线性组合。
假设 $z^{\cal T}_t = [1, 0, 0, 0, 0]$（即取标签 B），转换的结果正好是行向量 $\bold W^{tr}_{\rm B,:} $。 由于统一标签可以部分地从边界标签中导出，一个自然的问题是如何确定基于转换的统一标签分数 $z^{\cal S'}_t$ 的比例。 直观地，如果目标边界得分 $z^{\cal T}_t$ 接近均匀，表明边界标记器对其预测没有信心，则在统一标记上获得的分布，即 $z^{\cal S'}_t$ 也将接近均匀分布，并且对于情感预测几乎没有有意义的信息。 为了避免这种没有信息量 (uninformative) 的边界转换，我们根据目标边界标记器的置信度 $c_t$ 计算比例分数 $\alpha_t \in \mathbb R$：
$$
c_t=(z^{\cal T})^{\rm T} z^{\cal T} \\
\alpha_t=\epsilon c_t
\tag6
$$
其中超参数 $\epsilon$ 表示基于边界的分数 $z^{\cal S'}_t$ 在标记决策中所占的最大比例。 显然，如果边界分数均匀分布，则 $c_t$ 将被降低权重。 如果 $z^{\cal T}_t$ 是 one-hot 向量，则达到最大置信值。 结合基于边界和基于模型的统一标注分数得到最终分数：
$$
\tilde z^{\cal S}_t = \alpha_t z^{\cal S'}_t
+ (1-\alpha_t)z^{\cal S}_t
\tag7
$$

#### 2.2.3 保持情感一致性

在传统的目标情感分类任务中，通常假设对给定多词意见目标中不同词的情感是相同的。 然而，在完整的 TBSA 任务中，由于该任务被表述为序列标注 (tag) /标记 (label) 问题，因此无法保证这种情感一致性。以表 1 中的句子为例，由于 LSTMs 做出的独立标记决策，“Processor”一词仍有一定的可能性被标记为 E-NEG 标记。 为了保持同一意见目标内的情感一致性，我们建议使用当前和先前时间步的特征来预测当前的统一标签。 具体来说，我们设计了一个带有门机制的情感一致性 (SC) 组件来组合这两个特征向量：
$$
\tilde h^{\cal S}_t = g_t \odot h^{\cal S}_t +(1-g_t) \odot \tilde h^{\cal S}_{t-1} \\
g_t=\sigma (\bold W^g h^{\cal S}_t +\bold b^g)
\tag8
$$
其中 $\bold W_g$ 和 $\bold b_g$ 是 SC 组件的可学习参数，$\odot$表示元素乘法。  $\sigma$ 是 sigmoid 函数。 通过门控，当前预测中考虑了先前的特征，这种间接的二元组依赖可以帮助降低同一目标内的词持有不同情绪的概率。

#### 2.2.4 辅助目标词检测

一个好的意见目标边界标记器对于产生高质量的边界信息至关重要。 在这里，我们引入 OE 组件以从训练数据的另一个角度学习更强大的边界标记器。 正如 (Pontiki 2014; Pontiki 2015; Pontiki 2016) 中定义的那样，意见目标总是与意见词搭配在一起。 受此启发，如果该词的固定大小 $s$ 的上下文窗口内至少有一个意见词，我们将该词视为目标词。 然后，我们训练一个辅助的 token-level 分类器，用于基于远程监督标签区分目标词和非目标词，并且使用此类监督信号进一步细化边界表示 $h^{\cal T}_t$。  OE组件的计算过程如下：
$$
z^{\cal O}_t = {\rm Softmax}(\bold W^o h^{\cal T}_t)\\
y^{\cal O}_t = {\rm arg}\max_y z^{\cal O}_t
\tag9
$$
其中 $\bold W^o$ 是模型参数。

### 2.3 模型训练

我们框架中的所有组件都是可微的，因此，可以使用基于梯度的方法有效地训练整个框架。 使用词/token级交叉熵误差作为损失函数：

<img src="https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211007173402756.png" alt="image-20211007173402756" style="zoom: 67%;" />

其中 $\cal I$ 是任务指示符的符号，其可能的值是 $\cal T$ 、$\cal S$ 和 $\cal O$。 $\mathbb I(y)$ 表示第 $y$ 个分量为 1 的 one-hot 向量，$y^{\cal I,g}_t$ 是时间步 $t$ 的、任务 $\cal I$ 的黄金标准标签。 然后，将来自主要 TBSA 任务和两个辅助任务的损失聚合起来，形成框架的训练目标 $\cal J(θ)$：
$$
{\cal J}(\theta) = {\cal L^S}+ {\cal L^T}+ {\cal L^O}
\tag{11}
$$

## 3 实验



<img src="https://gitee.com/Wales-Z/image_bed/raw/master/img/image-20211007173139188.png" alt="image-20211007173139188" style="zoom:80%;" />

【表2】